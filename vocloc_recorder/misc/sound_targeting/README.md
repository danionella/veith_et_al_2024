# The sound targeting method

Code to play back a controlled sound stimulus in a tank. It is an impulse response-based method that works with one or many speakers. The basic idea is that one can define the target pressure or sound particle motion waveform in terms of their SI units and the code generates the sound files that -  when played back - produce these targets and actively cancel echoes.

### `soundtargeting.py`

The steps are
1. `rec_irs()`, hydrophone recordings of the impulse responses of each speaker.  <br/> 
    Saves: `impulse_responses.h5` (a dictionary with a nested dictionary for each speaker. The nested dictionaries contain the daq configuration and a list of hydrophone recordings for repeated delta pulse playbacks.)
2. `make_kernels()`, extraction of kernels in SI-units from recorded impulse responses. If one would like to define a target waveform in e.g. terms of pressure and particle acceleration along one axis, one has to define these observables with the following dictionary structure:
  
       obs = {"pressure": get_pressure,
              "acceleration_x": get_acceleration_x}
                
    The passed functions extract the observables from the raw recording, i.e. from hydrophones.
    For each observable and each speaker, a kernel is generated. Convolution of the signal with this kernel should predict the measurements in terms of the observables.  <br/> 
    Saves: `kernels.h5` (a dictionary with the structure
    
       kernels = {"pressure": [p_sp0, p_sp1, ...],
                  "acceleration_x": [a_sp0, a_sp1, ...]})
    where eg. `p_sp0` is the (average) pressure kernel generated by (repeated) playback of a delta pulse by speaker 0.
3. `find_sound()`, uses the kernels to generate conditioned sounds, that when played back produce the target waveform. One can define a target for each defined observable and the structure for this is a dictionary with this form:
         
       wav = 100 * gaussian_double_pulse() #some 1D target waveform, in Pascal 
       target = {"pressure": wav, "acceleration_x": 0 * wav} 
         
    In this example, the goal is to cancel all particle motion. The keys match the keys in `obs`. <br/>
    The function `save_sound()` saves the conditioned sound, the kernels and the target waveform and other metadata to `sound_*.h5`.<br/>
4. `rec_sound()` and `plot_sound_simulation(recorded=True)` can be used to see whether the measurement of the conditioned sound matches the prediction (i.e. the convolution of the sound with the kernels) and the defined targets.

### `soundtargeting_field.py`
This the generalization of `sound_targeting.py` to deliver targeted stimuli to multiple positions inside the tank. 
A system build from stepper motors moves the hydrophone or particle acceleration sensor over a grid to record impulse responses for each speaker at each position.
Sound conditioning is performed separately for each position.

The entry point is the `make_stimset` method: It 
- records the impulse responses
- computes the kernels
- generates the target waveforms from the wav folder
- finds the speaker activations that generate the target waveforms

The method `test_stimset` plays back all conditioned sounds and records the sound at all positions to validate sound conditioning results.
Validation plots can be generated via the `helper_notebooks > Underwater_acoustics.ipynb` notebook.

To check, whether the stimuli still generate the target waveforms at multiple days, one can track pressure and particle acceleration by calling the 
`measure_pfield_constancy` or the `measure_accelfield_constancy` method. Use the `helper_notebooks > FieldConstancy.ipynb` notebook for plotting this data.